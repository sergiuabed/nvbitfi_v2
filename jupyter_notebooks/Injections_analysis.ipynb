{"cells":[{"cell_type":"markdown","metadata":{"id":"R9NYC95T2kcb"},"source":["# This notebook performs analysis on the logs obtained from fault injection simulations on **PCAHyperspectralClassifier**."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":310,"status":"ok","timestamp":1722089822057,"user":{"displayName":"Sergiu Abed","userId":"04934986279206457690"},"user_tz":-120},"id":"7N3XBOPPCVQ_"},"outputs":[],"source":["DATASET = 'indianPines' #'pavia_uni' 'salinas'\n","INSTR_GROUP = 'G_FP32'# 'G_GP'\n","INSTR_GROUP_DICT = {'G_FP32': 1, 'G_GP': 7}\n","MACHINE = 'workstation'#'laptop' \n","PCA = 'PCA10'#'PCA50''PCA7'\n","HARDENING = True"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["'pca10_hardened_logs'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["LOGS_DICT = 'pca10_hardened_logs' if HARDENING else PCA.lower()+'_logs'\n","LOGS_DICT"]},{"cell_type":"markdown","metadata":{"id":"Syh8FydU-im2"},"source":["Unzip archive containing logs from NVBitFI"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["!rm -r analysis_cache\n","!mkdir analysis_cache"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":28739,"status":"ok","timestamp":1722089851059,"user":{"displayName":"Sergiu Abed","userId":"04934986279206457690"},"user_tz":-120},"id":"93bkASmZ2Saf"},"outputs":[],"source":["#!cp pca50_logs/{DATASET}_logs/{DATASET}_{PCA}_{INSTR_GROUP}.zip analysis_cache\n","#%cd analysis_cache\n","#!unzip {DATASET}_{PCA}_{INSTR_GROUP}.zip\n","#%cd logs/pca_hyperspectral/\n","\n","#!cp pca10_logs/{DATASET}_logs/{DATASET}_{PCA}_{INSTR_GROUP}_laptop.zip analysis_cache\n","#%cd analysis_cache\n","#!unzip {DATASET}_{PCA}_{INSTR_GROUP}_laptop.zip\n","#%cd logs/pca_hyperspectral/\n","\n","#!cp pca10_hardened_logs/{DATASET}_logs/{DATASET}_{PCA}_{INSTR_GROUP}_hardened.zip analysis_cache\n","#%cd analysis_cache\n","#!unzip {DATASET}_{PCA}_{INSTR_GROUP}_hardened.zip\n","#%cd logs/pca_hyperspectral/\n","\n","if HARDENING:\n","    !unzip {LOGS_DICT}/{DATASET}_logs/{DATASET}_{PCA}_{INSTR_GROUP}_hardened.zip -d analysis_cache\n","else:\n","    !unzip {LOGS_DICT}/{DATASET}_logs/{DATASET}_{PCA}_{INSTR_GROUP}.zip -d analysis_cache\n","\n","%cd analysis_cache/logs/pca_hyperspectral/\n","\n","#!unzip pca10_hardened_logs_new/{DATASET}_logs/{DATASET}_{PCA}_{INSTR_GROUP}_hardened.zip -d analysis_cache\n","#%cd analysis_cache/logs/pca_hyperspectral/\n","\n","#!unzip pca10_logs/{DATASET}_logs/{DATASET}_{PCA}_{INSTR_GROUP}.zip -d analysis_cache\n","#%cd analysis_cache/logs/pca_hyperspectral/"]},{"cell_type":"markdown","metadata":{"id":"ge7m0Fuv_clH"},"source":["# Create dataframe\n","Create dataframe from \"nvbitfi-injection-log-temp.txt\" files present in each subfolder of 'pca_hyperspectral'\n","\n","You will also need to save the \"golden_probabilities\" (i.e., the output logits of the neural network without any fault injected) and put them in the right directory (you can infer it from the cell below)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1722089896821,"user":{"displayName":"Sergiu Abed","userId":"04934986279206457690"},"user_tz":-120},"id":"8gMQVEO9-4hY"},"outputs":[],"source":["from genericpath import isfile\n","import os\n","import numpy as np\n","\n","# load golden probabilities\n","\n","#golden_probabilities = np.load(f'../../../pca10_logs/golden_probabilities/{DATASET}_{PCA}_golden_probabilities_{MACHINE}.npy')\n","#golden_probabilities = np.load(f'../../../pca10_hardened_logs/golden_probabilities/{DATASET}_{PCA}_hardened_golden_probabilities.npy')\n","golden_probabilities = np.load(f'../../../{LOGS_DICT}/golden_probabilities/{DATASET}_{PCA}_golden_probabilities_{MACHINE}.npy')\n","\n","list_dict = []\n","\n","for icount in range(1, 1001):\n","  #print(f'--------group: {group}  icount: {icount}--------')\n","  path = f'./pca_hyperspectral-group{INSTR_GROUP_DICT[INSTR_GROUP]}-model0-icount{icount}/nvbitfi-injection-log-temp.txt'\n","\n","  dict_line = {}\n","  dict_line['group'] = INSTR_GROUP_DICT[INSTR_GROUP]\n","  dict_line['icount'] = icount\n","\n","  # some injections results have 'nvbitfi-injection-log-temp.txt' empty. In these cases,\n","  # we can look at 'nvbitfi-injection-info.txt' to determine the target kernel\n","#    if not os.path.isfile(path):\n","#      print(f\"group: {group} icount: {icount}\")\n","\n","  if os.stat(path).st_size == 0:\n","    i = 0\n","    with open(f\"./pca_hyperspectral-group{INSTR_GROUP_DICT[INSTR_GROUP]}-model0-icount{icount}/nvbitfi-injection-info.txt\") as f:\n","      for line in f:\n","        if i == 2:\n","          dict_line['inspecting'] = line.strip()\n","        i += 1\n","\n","    if not os.path.isfile(f'./pca_hyperspectral-group{INSTR_GROUP_DICT[INSTR_GROUP]}-model0-icount{icount}/prediction_inference.tif'):\n","      dict_line['missing_output'] = True\n","\n","  if os.path.isfile(f'./pca_hyperspectral-group{INSTR_GROUP_DICT[INSTR_GROUP]}-model0-icount{icount}/diff.log'):\n","    # based on whether diff.log is empty or not we understand if the injection led to masked or sdc, respectively\n","    dict_line['diff_empty'] = (os.stat(f'./pca_hyperspectral-group{INSTR_GROUP_DICT[INSTR_GROUP]}-model0-icount{icount}/diff.log').st_size == 0)\n","\n","  with open(path) as f:\n","    for line in f:\n","\n","      if 'ERROR' in line:\n","        dict_line['ERROR'] = line\n","\n","        if 'inspecting' not in dict_line.keys():\n","          i = 0\n","          with open(f\"./pca_hyperspectral-group{INSTR_GROUP_DICT[INSTR_GROUP]}-model0-icount{icount}/nvbitfi-injection-info.txt\") as f:\n","            for line in f:\n","              if i == 2:\n","                dict_line['inspecting'] = line.strip()\n","              i += 1\n","\n","        break\n","\n","      if 'Injection data' in line:\n","        continue\n","\n","      l = line.strip().split(': ')\n","\n","      if l[0] == 'grp 0':\n","        grp_instr_counts = {}\n","\n","        #grp_instr_counts[l[2*i]] = l[2*i + 1]\n","        grp_instr_counts['grp 0'] = int(l[1].split(' ')[0])\n","        grp_instr_counts['grp 1'] = int(l[2].split(' ')[0])\n","        grp_instr_counts['grp 2'] = int(l[3].split(' ')[0])\n","        grp_instr_counts['grp 3'] = int(l[4].split(' ')[0])\n","        grp_instr_counts['grp 4'] = int(l[5].split(' ')[0])\n","        grp_instr_counts['grp 5'] = int(l[6].split(' ')[0])\n","        grp_instr_counts['grp 6'] = int(l[7].split(' ')[0])\n","        grp_instr_counts['grp 7'] = int(l[8].strip())\n","\n","        dict_line['counts per instr group'] = grp_instr_counts\n","\n","      elif l[0] == 'beforeVal':\n","        rest = l[1].strip().split(';')\n","        dict_line[l[0]] = rest[0]\n","\n","        #rest2 = rest[1].strip().split(': ')\n","        dict_line[rest[1]] = l[2]\n","\n","      else:\n","        dict_line[l[0]] = l[1]\n","\n","  list_dict.append(dict_line)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1722089896821,"user":{"displayName":"Sergiu Abed","userId":"04934986279206457690"},"user_tz":-120},"id":"ZqTIdX_SYhh3","outputId":"de8bf0ae-d345-4cab-dd24-a83c24ec3cda"},"outputs":[],"source":["len(list_dict)#d_empty"]},{"cell_type":"markdown","metadata":{"id":"BMNI9JBbvqSN"},"source":["Trim kernel names"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1722089896821,"user":{"displayName":"Sergiu Abed","userId":"04934986279206457690"},"user_tz":-120},"id":"ZuPi3Gxhvp-H"},"outputs":[],"source":["# some of the (static) kernels share the same name but have different parameters. To avoid mapping two different kernels to the same name,\n","# we use this dict to map each kernel to a unique name\n","common_kern_names = {'voidgemv2T_kernel_val<int,int,float,float,float,float,128,16,4,4,false,false,cublasGemvParams<cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<float>,float>>(cublasGemvParams<cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<float>,float>,float,float)': 'voidgemv2T_kernel_val_VER1',\n","                     'voidgemv2T_kernel_val<int,int,float,float,float,float,128,16,2,2,false,false,cublasGemvParams<cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<float>,float>>(cublasGemvParams<cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<float>,float>,float,float)': 'voidgemv2T_kernel_val_VER2',\n","                     'voidsplitKreduce_kernel<32,16,int,float,float,float,float,true,false,false>(cublasSplitKParams<float>,floatconst*,floatconst*,float*,floatconst*,floatconst*,floatconst*,floatconst*,float*,void*,long,float*,int*)': 'voidsplitKreduce_kernel_VER1',\n","                     'voidsplitKreduce_kernel<32,16,int,float,float,float,float,true,true,false>(cublasSplitKParams<float>,floatconst*,floatconst*,float*,floatconst*,floatconst*,floatconst*,floatconst*,float*,void*,long,float*,int*)': 'voidsplitKreduce_kernel_VER2',\n","                     'voidgemv2N_kernel<int,int,float,float,float,float,128,4,4,4,1,false,cublasGemvParams<cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<float>,float>>(cublasGemvParams<cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<float>,float>)': 'voidgemv2N_kernel_VER1',\n","                     'voidgemv2N_kernel<int,int,float,float,float,float,128,1,4,4,1,false,cublasGemvParams<cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<float>,float>>(cublasGemvParams<cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<float>,float>)': 'voidgemv2N_kernel_VER2',\n","                     'voidgemv2N_kernel<int,int,float,float,float,float,128,2,4,4,1,false,cublasGemvParams<cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<float>,float>>(cublasGemvParams<cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<floatconst>,cublasGemvTensorStridedBatched<float>,float>)': 'voidgemv2N_kernel_VER3',\n","                     'voidat::native::elementwise_kernel<128,2,at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()()const::{lambda()#14}::operator()()const::{lambda(float)#1}>(at::TensorIteratorBase&,at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()()const::{lambda()#14}::operator()()const::{lambda(float)#1}const&)::{lambda(int)#1}>(int,at::native::gpu_kernel_impl<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()()const::{lambda()#14}::operator()()const::{lambda(float)#1}>(at::TensorIteratorBase&,at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()()const::{lambda()#14}::operator()()const::{lambda(float)#1}const&)::{lambda(int)#1})': 'elementwise_kernel_VER1',\n","                     'voidat::native::elementwise_kernel<128,2,at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<float>>(at::TensorIteratorBase&,at::native::CUDAFunctor_add<float>const&)::{lambda(int)#1}>(int,at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<float>>(at::TensorIteratorBase&,at::native::CUDAFunctor_add<float>const&)::{lambda(int)#1})': 'elementwise_kernel_VER2',\n","                     'sm80_xmma_fprop_implicit_gemm_indexed_tf32f32_tf32f32_f32_nhwckrsc_nhwc_tilesize128x128x16_stage4_warpsize2x2x1_g1_tensor16x8x8_kernel_cudnn': 'nhwckrsc_nhwc_tilesize128x128x16_stage4'}\n","\n","for i in range(len(list_dict)):#['kernel_name'].unique():\n","  if 'inspecting' not in list_dict[i].keys():\n","    continue\n","\n","  if list_dict[i]['inspecting'] in common_kern_names.keys():\n","    list_dict[i]['inspecting'] = common_kern_names[list_dict[i]['inspecting']]\n","\n","  if 'computeBOffsetsKernel' in list_dict[i]['inspecting']:\n","    list_dict[i]['inspecting'] = 'computeBOffsetsKernel'\n","\n","  if '<' in list_dict[i]['inspecting']:\n","    list_dict[i]['inspecting'] = list_dict[i]['inspecting'].strip().split('<')[0]\n","    #print(kern_name)\n","\n","  if '::' in list_dict[i]['inspecting']:\n","    list_dict[i]['inspecting'] = list_dict[i]['inspecting'].strip().split(\"::\")[-1]\n"]},{"cell_type":"markdown","metadata":{"id":"3BTSIM6H8k1D"},"source":["# Create list of injections leading to Critical SDCs\n","\n","note: Safe SDCs are included in Masked results. They will be extracted later on.\n","\n","IMPORTANT: Everytime you rerun fault injections, make sure to delete the logs inside 'nvbitfi/logs/pca_hyperspectral'. Otherwise the second run of injections will overwrite on the previous one and get mixed results with the previous simulation!\n","\n","IMPORTANT: always check the existence of 'prediction_inference.tif'. NVBitFI will still give an empty \"diff.log\" when 'prediction_inference.tif' is not produced, which can be mistaken for Masked OR SDC-safe. In such a situation, \"nvbitfi-injection-log-temp.txt\" should contain the word error."]},{"cell_type":"markdown","metadata":{"id":"PhXNHfgjMStb"},"source":["We have 3 types of injection outcomes:\n","1. \"nvbitfi-injection-log-temp.txt\" w/o 'ERROR' word inside\n","2. \"nvbitfi-injection-log-temp.txt\" with 'ERROR' word inside\n","3. \"nvbitfi-injection-log-temp.txt\" empty"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2144,"status":"ok","timestamp":1722089898962,"user":{"displayName":"Sergiu Abed","userId":"04934986279206457690"},"user_tz":-120},"id":"JRYDPbPZebZo"},"outputs":[],"source":["d_clean = [d for d in list_dict if 'ERROR' not in d.keys() and len(d.keys()) == 18 ]\n","d_error = [d for d in list_dict if 'ERROR' in d.keys()]\n","d_empty = [d for d in list_dict if 'ERROR' not in d.keys() and len(d.keys()) < 18]\n","\n","#golden_probabilities = np.load('logs/golden_probabilities.npy')\n","\n","def is_sdc_safe(icount):\n","\n","  #np.load('logs_part1/pca_hyperspectral/pca_hyperspectral-group1-model0-icount1/probabilities.npy')\n","  probabilities = np.load(f'./pca_hyperspectral-group{INSTR_GROUP_DICT[INSTR_GROUP]}-model0-icount{icount}/probabilities.npy')\n","\n","  expected_matches = golden_probabilities.shape[0] * golden_probabilities.shape[1] * golden_probabilities.shape[2]\n","\n","  # this checks if some of the classifications are different\n","  # returns true if there is at least one miscalssification\n","  return (golden_probabilities == probabilities).sum() != expected_matches\n","\n","# get masked and sdc from d_clean\n","d_sdc_critical = [d for d in d_clean if d['diff_empty'] is False]\n","d_masked = [d for d in d_clean if (d['diff_empty'] is True) and (not is_sdc_safe(d['icount']))]\n","d_sdc_safe = [d for d in d_clean if (d['diff_empty'] is True) and is_sdc_safe(d['icount'])]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(d_masked)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#golden_probabilities = np.load(f'../../golden_probabilities.npy')\n","golden_probabilities = np.load(f'../../../pca10_logs/golden_probabilities/{DATASET}_PCA10_golden_probabilities_{MACHINE}.npy')\n","probabilities = np.load(f'./pca_hyperspectral-group{INSTR_GROUP_DICT[INSTR_GROUP]}-model0-icount{9}/probabilities.npy')\n","n = golden_probabilities - probabilities\n","print(n.min())\n","print(n.max())\n","#print(is_sdc_safe(9))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["INSTR_GROUP"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1722089898962,"user":{"displayName":"Sergiu Abed","userId":"04934986279206457690"},"user_tz":-120},"id":"56jdPlo04pmd","outputId":"32bba1aa-0bb1-4ae4-c335-e252067c9ed4"},"outputs":[],"source":["print(f'Nr outcomes that are not DUEs: {len(d_masked) + len(d_sdc_safe) + len(d_sdc_critical)}')\n","print(f'Nr Masked: {len(d_masked)}')\n","print(f'Nr SDC-safe: {len(d_sdc_safe)}')\n","print(f'Nr SDC-critical: {len(d_sdc_critical)}')"]},{"cell_type":"markdown","metadata":{"id":"24z14rzFN3y3"},"source":["# Create dataframes"]},{"cell_type":"markdown","metadata":{},"source":["note: for some error outcomes NVBitFI might not report which kernel, opcode and register was targeted and so, some of the lines below will result in error. Comment them accordingly. "]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":650,"status":"ok","timestamp":1722089900220,"user":{"displayName":"Sergiu Abed","userId":"04934986279206457690"},"user_tz":-120},"id":"Ncc-96IJMii9"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["import pandas as pd\n","\n","# errors dataframe\n","df_error = pd.DataFrame(d_error)\n","\n","if INSTR_GROUP == 'G_GP':\n","  df_error2 = df_error[df_error['inspecting'].notnull()].iloc[:, 3:4] #[:, 2:3] #HERE YOU MIGHT HAVE TO CHANGE iloc INDEXING TO SELECT THE COLUMN 'inspecting'\n","\n","  kernel_error_counts = df_error2.groupby('inspecting').value_counts()\n","  #opcode_error_counts = df_error[df_error['opcode'].notnull()].iloc[:, 15:16].groupby('opcode').value_counts()\n","  #register_error_counts = df_error[df_error['regNo'].notnull()].iloc[:, 14:15].groupby('regNo').value_counts()\n","  opcode_error_counts = df_error[df_error['opcode'].notnull()].iloc[:, 11:12].groupby('opcode').value_counts()\n","  register_error_counts = df_error[df_error['regNo'].notnull()].iloc[:, 10:11].groupby('regNo').value_counts()\n","\n","else:\n","  print()\n","  df_error2 = df_error[df_error['inspecting'].notnull()].iloc[:, 3:4] #[:, 2:3]\n","\n","  #df_error2 = df_error[df_error['inspecting'].notnull()].iloc[:, 2:3] #[:, 2:3]\n","\n","  kernel_error_counts = df_error2.groupby('inspecting').value_counts()\n","  #opcode_error_counts = df_error[df_error['opcode'].notnull()].iloc[:, 12:13].groupby('opcode').value_counts()\n","  #register_error_counts = df_error[df_error['regNo'].notnull()].iloc[:, 11:12].groupby('regNo').value_counts()\n","  opcode_error_counts = df_error[df_error['opcode'].notnull()].iloc[:, 11:12].groupby('opcode').value_counts()\n","  register_error_counts = df_error[df_error['regNo'].notnull()].iloc[:, 10:11].groupby('regNo').value_counts()\n","\n","  #opcode_error_counts = df_error[df_error['opcode'].notnull()].iloc[:, 14:15].groupby('opcode').value_counts()\n","  #register_error_counts = df_error[df_error['regNo'].notnull()].iloc[:, 13:14].groupby('regNo').value_counts()\n","\n","# sdcs_critical dataframe\n","df_sdc_critical = pd.DataFrame(d_sdc_critical)\n","\n","kernel_sdc_critical_counts = df_sdc_critical.iloc[:, 3:4].groupby('inspecting').value_counts()\n","opcode_sdc_critical_counts = df_sdc_critical.iloc[:, 15:16].groupby('opcode').value_counts()\n","register_sdc_critical_counts = df_sdc_critical.iloc[:, 14:15].groupby('regNo').value_counts()\n","\n","# sdcs_safe\n","df_sdc_safe = pd.DataFrame(d_sdc_safe)\n","\n","kernel_sdc_safe_counts = df_sdc_safe.iloc[:, 3:4].groupby('inspecting').value_counts()\n","opcode_sdc_safe_counts = df_sdc_safe.iloc[:, 15:16].groupby('opcode').value_counts()\n","register_sdc_safe_counts = df_sdc_safe.iloc[:, 14:15].groupby('regNo').value_counts()\n","\n","# masked dataframe\n","df_masked = pd.DataFrame(d_masked)\n","\n","kernel_masked_counts = df_masked.iloc[:, 3:4].groupby('inspecting').value_counts()\n","opcode_masked_counts = df_masked.iloc[:, 15:16].groupby('opcode').value_counts()\n","register_masked_counts = df_masked.iloc[:, 14:15].groupby('regNo').value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if HARDENING:\n","    df_error.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/complete_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_dataframes.h5', 'df_error')\n","    df_sdc_critical.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/complete_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_dataframes.h5', 'df_sdc_critical')\n","    df_sdc_safe.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/complete_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_dataframes.h5', 'df_sdc_safe')\n","    df_masked.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/complete_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_dataframes.h5', 'df_masked')\n","else:\n","    df_error.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/complete_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_dataframes.h5', 'df_error')\n","    df_sdc_critical.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/complete_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_dataframes.h5', 'df_sdc_critical')\n","    df_sdc_safe.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/complete_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_dataframes.h5', 'df_sdc_safe')\n","    df_masked.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/complete_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_dataframes.h5', 'df_masked')\n"]},{"cell_type":"markdown","metadata":{},"source":["Save counts"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["if HARDENING:\n","    #kernels\n","    kernel_sdc_critical_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_counts.h5', key='kernel_sdc_critical_counts')#df_normal.to_hdf('normal_and_attacked_dfs.h5', key='df_normal')\n","    kernel_sdc_safe_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_counts.h5', key='kernel_sdc_safe_counts')\n","    kernel_masked_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_counts.h5', key='kernel_masked_counts')\n","    kernel_error_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_counts.h5', key='kernel_error_counts')\n","    \n","    #opcodes\n","    opcode_sdc_critical_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_counts.h5', key='opcode_sdc_critical_counts')\n","    opcode_sdc_safe_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_counts.h5', key='opcode_sdc_safe_counts')\n","    opcode_masked_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_counts.h5', key='opcode_masked_counts')\n","    opcode_error_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_counts.h5', key='opcode_error_counts')\n","    \n","    #registers\n","    register_sdc_critical_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_counts.h5', key='register_sdc_critical_counts')\n","    register_sdc_safe_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_counts.h5', key='register_sdc_safe_counts')\n","    register_masked_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_counts.h5', key='register_masked_counts')\n","    register_error_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_counts.h5', key='register_error_counts')\n","else:\n","    #kernels\n","    kernel_sdc_critical_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_counts.h5', key='kernel_sdc_critical_counts')#df_normal.to_hdf('normal_and_attacked_dfs.h5', key='df_normal')\n","    kernel_sdc_safe_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_counts.h5', key='kernel_sdc_safe_counts')\n","    kernel_masked_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_counts.h5', key='kernel_masked_counts')\n","    kernel_error_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_counts.h5', key='kernel_error_counts')\n","\n","    #opcodes\n","    opcode_sdc_critical_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_counts.h5', key='opcode_sdc_critical_counts')\n","    opcode_sdc_safe_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_counts.h5', key='opcode_sdc_safe_counts')\n","    opcode_masked_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_counts.h5', key='opcode_masked_counts')\n","    opcode_error_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_counts.h5', key='opcode_error_counts')\n","\n","    #registers\n","    register_sdc_critical_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_counts.h5', key='register_sdc_critical_counts')\n","    register_sdc_safe_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_counts.h5', key='register_sdc_safe_counts')\n","    register_masked_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_counts.h5', key='register_masked_counts')\n","    register_error_counts.to_hdf(f'../../../kernels_sdc_critical_counts_dataframes/counts_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_counts.h5', key='register_error_counts')"]},{"cell_type":"markdown","metadata":{"id":"7HTqUmJn1s3-"},"source":["# Jaccard similarity coefficient"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":256,"status":"ok","timestamp":1722089910647,"user":{"displayName":"Sergiu Abed","userId":"04934986279206457690"},"user_tz":-120},"id":"b3yQjmYQummR"},"outputs":[],"source":["def jaccard_index(golden_logits, logits):\n","  num_classes = golden_logits.shape[2]\n","\n","  #inference is done by selecting the index along the 3rd dimension (2nd in numpy) corresponding to the highest value\n","  golden_inference = golden_logits.argmax(axis=2)\n","  inference = logits.argmax(axis=2)\n","\n","  jaccard_idx = []\n","  for clss in range(num_classes):\n","    #masking: set each value in 'golden_inference' and 'inference' to:\n","    #         - True, if it's equal to class 'cls'\n","    #         - False, otherwise\n","\n","    masked_golden_inference = golden_inference == clss\n","    masked_inference = inference == clss\n","\n","    # intersection over union\n","    j_idx = (masked_golden_inference * masked_inference).sum() / (masked_golden_inference + masked_inference).sum()\n","\n","    jaccard_idx.append(j_idx)\n","\n","  return jaccard_idx\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1010,"status":"ok","timestamp":1722089915433,"user":{"displayName":"Sergiu Abed","userId":"04934986279206457690"},"user_tz":-120},"id":"GzqMF_8SZfz8","outputId":"d0bf5fc1-c3ce-4bdf-eae0-e287d4e604b4"},"outputs":[],"source":["df_sdc_critical_j = df_sdc_critical.copy(deep=True)\n","\n","ji = [min(jaccard_index(golden_probabilities, np.load(f'./pca_hyperspectral-group{INSTR_GROUP_DICT[INSTR_GROUP]}-model0-icount{icount}/probabilities.npy'))) for icount in df_sdc_critical.iloc[:, 1]]\n","\n","ji_bad = [i for i in ji if i < 0.99]\n","ji_bad"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":242,"status":"ok","timestamp":1722089932227,"user":{"displayName":"Sergiu Abed","userId":"04934986279206457690"},"user_tz":-120},"id":"dRW4coYO_krL","outputId":"58ed74e1-ef86-4070-de56-987e7091a0bc"},"outputs":[],"source":["idxs = []\n","for i in range(len(ji)):\n","  if ji[i] in ji_bad:\n","    idxs.append(i)\n","\n","#df_sdc_critical.iloc[idxs[1], :]\n","df_sdc_critical_significant = df_sdc_critical.iloc[idxs, :].copy(deep=True)\n","df_sdc_critical_significant"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_js = pd.DataFrame({'jaccard_similarity': ji})\n","df_sdc_critical_enhanced = pd.concat([df_sdc_critical, df_js], axis=1)\n","\n","df_sdc_critical_enhanced[df_sdc_critical_enhanced['jaccard_similarity'] < 0.99]"]},{"cell_type":"markdown","metadata":{"id":"gW1JhFcvhxxU"},"source":["# Change in logits (SDC-safe and SDC-critical cases)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":670,"status":"ok","timestamp":1722092362124,"user":{"displayName":"Sergiu Abed","userId":"04934986279206457690"},"user_tz":-120},"id":"wlvQ2HVRiDDM"},"outputs":[],"source":["def softmax(a):\n","  return np.exp(a)/sum(np.exp(a))\n","\n","safe_logits_change_ds = {}#pd.Series(dtype=np.float64)\n","safe_logits_change_list = []\n","#probs_change_ds = {}#pd.Series(dtype=np.float64)\n","\n","critical_logits_change_ds = {}\n","critical_logits_change_list = []\n","critical_probs_change_ds = {}\n","\n","for icount in df_sdc_safe['icount']:\n","  probabilities = np.load(f'./pca_hyperspectral-group{INSTR_GROUP_DICT[INSTR_GROUP]}-model0-icount{icount}/probabilities.npy')\n","\n","  safe_logits_change_ds[icount] = np.linalg.norm(golden_probabilities - probabilities)/np.linalg.norm(golden_probabilities)\n","  safe_logits_change_list.append(safe_logits_change_ds[icount])\n","\n","for icount in df_sdc_critical['icount']:\n","  probabilities = np.load(f'./pca_hyperspectral-group{INSTR_GROUP_DICT[INSTR_GROUP]}-model0-icount{icount}/probabilities.npy')\n","\n","  critical_logits_change_ds[icount] = np.linalg.norm(golden_probabilities - probabilities)/np.linalg.norm(golden_probabilities)\n","  critical_logits_change_list.append(critical_logits_change_ds[icount])"]},{"cell_type":"markdown","metadata":{},"source":["cell below is the same as the one above, but with some changes for checking some details"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#golden_probabilities.shape\n","safe_logits_change_list"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["#critical_logits_change_list\n","df_critical_logits_change = pd.DataFrame({'logits_degradation': critical_logits_change_list})\n","df_sdc_critical_enhanced = pd.concat([df_sdc_critical_enhanced, df_critical_logits_change], axis=1)\n","\n","df_safe_logits_change = pd.DataFrame({'logits_degradation': safe_logits_change_list})\n","df_sdc_safe_enhanced = pd.concat([df_sdc_safe, df_safe_logits_change], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1722092378896,"user":{"displayName":"Sergiu Abed","userId":"04934986279206457690"},"user_tz":-120},"id":"nnBpt9YJj2rE","outputId":"e23c5ef9-4306-4fab-d568-298371260eb4"},"outputs":[],"source":["max_safe_logits_change = max(safe_logits_change_ds.values())\n","\n","print(f'Highest change in logits in SDC-safe cases: {max(safe_logits_change_ds.values())}')\n","print(f'Highest change in logits in SDC-critical cases: {max(critical_logits_change_ds.values())}')#.min()\n","\n","#np.linalg.norm(golden_probabilities)\n","#max(probs_change_ds.values())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#sort(safe_logits_change_ds, )\n","sorted_safe_logits_change = sorted(safe_logits_change_ds.items(), key=lambda x: x[1], reverse=True)\n","sorted_critical_logits_change = sorted(critical_logits_change_ds.items(), key=lambda x: x[1], reverse=True)\n","\n","sorted_critical_logits_change\n","#sorted_safe_logits_change"]},{"cell_type":"markdown","metadata":{},"source":["# Confusion Matrix"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["from scipy import io, misc\n","\n","def open_file(dataset):\n","    _, ext = os.path.splitext(dataset)\n","    ext = ext.lower()\n","    if ext == '.mat':\n","        # Load Matlab array\n","        return io.loadmat(dataset)\n","    else:\n","        raise ValueError(\"Unknown file format: {}\".format(ext))"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["label_values_paviaU = [\n","            \"Undefined\",\n","            \"Asphalt\",\n","            \"Meadows\",\n","            \"Gravel\",\n","            \"Trees\",\n","            \"Painted metal sheets\",\n","            \"Bare Soil\",\n","            \"Bitumen\",\n","            \"Self-Blocking Bricks\",\n","            \"Shadows\",\n","        ]\n","\n","label_values_salinas = [\n","            \"Undefined\",\n","            \"Brocoli_green_weeds_1\",\n","            \"Brocoli_green_weeds_2\",\n","            \"Fallow\",\n","            \"Fallow_rough_plow\",\n","            \"Fallow_smooth\",\n","            \"Stubble\",\n","            \"Celery\",\n","            \"Grapes_untrained\",\n","            \"Soil_vinyard_develop\",\n","            \"Corn_senesced_green_weeds\",\n","            \"Lettuce_romaine_4wk\",\n","            \"Lettuce_romaine_5wk\",\n","            \"Lettuce_romaine_6wk\",\n","            \"Lettuce_romaine_7wk\",\n","            \"Vinyard_untrained\",\n","            \"Vinyard_vertical_trellis\",\n","        ]\n","\n","label_values_indianPines = [\n","            \"Undefined\",\n","            \"Alfalfa\",\n","            \"Corn-notill\",\n","            \"Corn-mintill\",\n","            \"Corn\",\n","            \"Grass-pasture\",\n","            \"Grass-trees\",\n","            \"Grass-pasture-mowed\",\n","            \"Hay-windrowed\",\n","            \"Oats\",\n","            \"Soybean-notill\",\n","            \"Soybean-mintill\",\n","            \"Soybean-clean\",\n","            \"Wheat\",\n","            \"Woods\",\n","            \"Buildings-Grass-Trees-Drives\",\n","            \"Stone-Steel-Towers\",\n","        ]\n","\n","datasetPath_dict  = {'pavia_uni': 'PaviaU', 'salinas': 'Salinas', 'indianPines': 'IndianPines'}\n","datasetName_dict = {'pavia_uni': 'PaviaU_gt.mat', 'salinas': 'Salinas_gt.mat', 'indianPines': 'Indian_pines_gt.mat'}\n","datasetLabels_dict = {'pavia_uni': label_values_paviaU, 'salinas': label_values_salinas, 'indianPines': label_values_indianPines}\n","datasetDumb_dict = {'pavia_uni': 'paviaU_gt', 'salinas': 'salinas_gt', 'indianPines': 'indian_pines_gt'}\n","\n","gt_path = f'../../../Datasets/{datasetPath_dict[DATASET]}/{datasetName_dict[DATASET]}'\n","\n","gt = open_file(gt_path)[datasetDumb_dict[DATASET]]"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"l_m44vS6q2gU"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","#import visdom\n","\n","def metrics(prediction, target, ignored_labels=[], n_classes=None,k=None):\n","    \"\"\"Compute and print metrics (accuracy, confusion matrix and F1 scores).\n","\n","    Args:\n","        prediction: list of predicted labels\n","        target: list of target labels\n","        ignored_labels (optional): list of labels to ignore, e.g. 0 for undef\n","        n_classes (optional): number of classes, max(target) by default\n","    Returns:\n","        accuracy, F1 score by class, confusion matrix\n","    \"\"\"\n","    ignored_mask = np.zeros(target.shape[:2], dtype=\"bool\")\n","    for l in ignored_labels:\n","        ignored_mask[target == l] = True\n","    ignored_mask = ~ignored_mask\n","    target = target[ignored_mask]\n","    prediction = prediction[ignored_mask]\n","\n","    results = {}\n","\n","    n_classes = np.max(target) + 1 if n_classes is None else n_classes\n","\n","    cm = confusion_matrix(\n","        target,\n","        prediction,\n","        labels=range(n_classes))\n","\n","    results[\"Confusion matrix\"] = cm\n","\n","    # Compute global accuracy  VP + VN / VP+VN +TN +TP\n","    total = np.sum(cm)\n","    accuracy = sum([cm[x][x] for x in range(len(cm))])\n","    accuracy *= 100 / float(total)\n","\n","    # with open('acc150-5.txt', 'a') as f:\n","    #     f.write(f\"K={k} : {str(accuracy)}\")\n","\n","    results[\"Accuracy\"] = accuracy\n","\n","    # Compute F1 score // accuratezza test    Precision = VP/ FP+TP recall = VP/VP+FN   F1 = media armonica = 2 * ((p*r)/(p+r))\n","    F1scores = np.zeros(len(cm))\n","    for i in range(len(cm)):\n","        try:\n","            F1 = 2. * cm[i, i] / (np.sum(cm[i, :]) + np.sum(cm[:, i]))\n","        except ZeroDivisionError:\n","            F1 = 0.\n","        F1scores[i] = F1\n","\n","    results[\"F1 scores\"] = F1scores\n","\n","    pa = np.trace(cm) / float(total)\n","    pe = np.sum(np.sum(cm, axis=0) * np.sum(cm, axis=1)) / \\\n","        float(total * total)\n","    kappa = (pa - pe) / (1 - pe)\n","    results[\"Kappa\"] = kappa\n","\n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#probs = np.load(f'../../../pca10_logs/golden_probabilities/{DATASET}_{PCA}_golden_probabilities_{MACHINE}.npy')\n","#probs = np.load(f'../../../pca10_hardened_logs/golden_probabilities/{DATASET}_{PCA}_hardened_golden_probabilities.npy')\n","probs = np.load(f'../../../{LOGS_DICT}/golden_probabilities/{DATASET}_{PCA}_golden_probabilities_{MACHINE}.npy')\n","\n","label_values = datasetLabels_dict[DATASET]\n","\n","prediction = np.argmax(probs, axis=-1)\n","\n","run_results = metrics(prediction, gt, [0], len(label_values)) #[0]\n","cm = run_results[\"Confusion matrix\"]\n","golden_accuracy = run_results[\"Accuracy\"]\n","golden_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ics = []\n","accs = []\n","for ic in df_sdc_critical.iloc[:, 1]:\n","    probs = np.load(f'./pca_hyperspectral-group{INSTR_GROUP_DICT[INSTR_GROUP]}-model0-icount{ic}/probabilities.npy')\n","\n","    label_values = datasetLabels_dict[DATASET]\n","\n","    prediction = np.argmax(probs, axis=-1)\n","\n","    run_results = metrics(prediction, gt, [0], len(label_values)) #[0]\n","    cm = run_results[\"Confusion matrix\"]\n","    accuracy = run_results[\"Accuracy\"]\n","    accs.append(accuracy)\n","    if accuracy < (golden_accuracy - 0.001):\n","        print((ic, accuracy))\n","        ics.append(ic)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["accs_arr = np.array(accs)\n","golden_accs_arr = np.array([golden_accuracy for _ in accs])\n","acc_drop = golden_accs_arr - accs_arr\n","\n","df_acc_drop = pd.DataFrame({'accuracy_drop': acc_drop})\n","df_accuracies = pd.DataFrame({'accuracy': accs})\n","\n","df_sdc_critical_enhanced = pd.concat([df_sdc_critical_enhanced, df_accuracies, df_acc_drop], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%cd ../../.."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_sdc_critical_enhanced"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#df_sdc_critical_enhanced.to_hdf(f'./kernels_sdc_critical_counts_dataframes/complete_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_dataframes.h5', 'df_sdc_critical_enhanced')\n","#df_sdc_safe_enhanced.to_hdf(f'./kernels_sdc_critical_counts_dataframes/complete_dataframes/{MACHINE}_{PCA}_{DATASET}_{INSTR_GROUP}_dataframes.h5', 'df_sdc_safe_enhanced')\n","\n","df_sdc_critical_enhanced.to_hdf(f'./kernels_sdc_critical_counts_dataframes/complete_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_dataframes.h5', 'df_sdc_critical_enhanced')\n","df_sdc_safe_enhanced.to_hdf(f'./kernels_sdc_critical_counts_dataframes/complete_dataframes/{MACHINE}_{PCA}_hardened_{DATASET}_{INSTR_GROUP}_dataframes.h5', 'df_sdc_safe_enhanced')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#df_final = df_sdc_critical_enhanced#.copy(deep=True)\n","df_sdc_critical_enhanced[df_sdc_critical_enhanced['accuracy_drop'] > 0.0]"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNGNQd09hbHweueH58GGEcM","mount_file_id":"18liGvPbx6bjOX2NsYNfFrK9kWXQZoBN0","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
